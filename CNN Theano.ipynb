{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_rate(p, t):\n",
    "    return np.mean(p!=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(a):\n",
    "    return a*(a>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def y2indicator(y):\n",
    "    N = len(y)\n",
    "    ind = np.zeros((N, 10))\n",
    "    for i in range(N):\n",
    "        ind[i, y[i]] = 1\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_pool(X, W, b, poolsize=(2,2)):\n",
    "    conv_out = conv2d(input=X, filters=W)\n",
    "    pool_out = pool.pool_2d(\n",
    "        input=conv_out,\n",
    "        ws=poolsize,\n",
    "        ignore_border=True\n",
    "    )\n",
    "    \n",
    "    return relu(pool_out + b.dimshuffle('x', 0, 'x', 'x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_filter(shape, poolsz):\n",
    "    w = np.random.randn(*shape) / np.sqrt(np.prod(shape[:-1]) + shape[-1]*np.prod(shape[:-2] / np.prod(poolsz)))\n",
    "    return w.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rearrange(X):\n",
    "    return (X.transpose(3, 2, 0, 1) / 255).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    train = loadmat('../data/train_32x32.mat')\n",
    "    test = loadmat('../data/test_32x32.mat')\n",
    "    \n",
    "    Xtrain = rearrange(train['X'])\n",
    "    Ytrain = train['y'].flatten() - 1\n",
    "    del train\n",
    "    Xtrain, Ytrain = shuffle(Xtrain, Ytrain)\n",
    "    Ytrain_ind = y2indicator(Ytrain)\n",
    "    \n",
    "    Xtest = rearrange(test['X'])\n",
    "    Ytest = test['y'].flatten() - 1\n",
    "    del test\n",
    "    Ytest_ind = y2indicator(Ytest)\n",
    "    \n",
    "    max_iter = 20\n",
    "    print_period = 10\n",
    "    \n",
    "    lr = np.float32(0.00001)\n",
    "    reg = np.float32(0.01)\n",
    "    mu = np.float32(0.99)\n",
    "    \n",
    "    N = Xtrain.shape[0]\n",
    "    batch_sz = 500\n",
    "    n_batch = N // batch_sz\n",
    "    \n",
    "    M = 500\n",
    "    K = 10\n",
    "    poolsz = (2, 2)\n",
    "    \n",
    "    W1_shape = (20, 3, 5, 5)\n",
    "    W1_init = init_filter(W1_shape, poolsz)\n",
    "    b1_init = np.zeros(W1_shape[0], dtype=np.float32)\n",
    "    \n",
    "    W2_shape = (50, 20, 5, 5)\n",
    "    W2_init = init_filter(W2_shape, poolsz)\n",
    "    b2_init = np.zeros(W2_shape[0], dtype=np.float32)\n",
    "    \n",
    "    W3_init = np.random.randn(W2_shape[0]*5*5, M) / np.sqrt(W2_shape[0]*5*5 + M)\n",
    "    b3_init = np.zeros(M, dtype=np.float32)\n",
    "    \n",
    "    W4_init = np.random.randn(M, K) / np.sqrt(M + K)\n",
    "    b4_init = np.zeros(K, dtype=np.float32)\n",
    "    \n",
    "    X = T.tensor4('X', dtype='float32')\n",
    "    Y = T.matrix('T')\n",
    "    \n",
    "    W1 = theano.shared(W1_init, 'W1')\n",
    "    b1 = theano.shared(b1_init, 'b1')\n",
    "    W2 = theano.shared(W2_init, 'W2')\n",
    "    b2 = theano.shared(b2_init, 'b2')\n",
    "    W3 = theano.shared(W3_init.astype(np.float32), 'W3')\n",
    "    b3 = theano.shared(b3_init, 'b3')\n",
    "    W4 = theano.shared(W4_init.astype(np.float32), 'W4')\n",
    "    b4 = theano.shared(b4_init, 'b4')\n",
    "    \n",
    "    dW1 = theano.shared(np.zeros(W1_init.shape, dtype=np.float32), 'dW1')\n",
    "    db1 = theano.shared(np.zeros(b1_init.shape, dtype=np.float32), 'db1')\n",
    "    dW2 = theano.shared(np.zeros(W2_init.shape, dtype=np.float32), 'dW2')\n",
    "    db2 = theano.shared(np.zeros(b2_init.shape, dtype=np.float32), 'db2')\n",
    "    dW3 = theano.shared(np.zeros(W3_init.shape, dtype=np.float32), 'dW3')\n",
    "    db3 = theano.shared(np.zeros(b3_init.shape, dtype=np.float32), 'db3')\n",
    "    dW4 = theano.shared(np.zeros(W4_init.shape, dtype=np.float32), 'dW4')\n",
    "    db4 = theano.shared(np.zeros(b4_init.shape, dtype=np.float32), 'db4')\n",
    "    \n",
    "    Z1 = conv_pool(X, W1, b1)\n",
    "    Z2 = conv_pool(Z1, W2, b2)\n",
    "    Z3 = relu(Z2.flatten(ndim=2).dot(W3) + b3)\n",
    "    pY = T.nnet.softmax(Z3.dot(W4) + b4)\n",
    "    \n",
    "    params = (W1, b1, W2, b2, W3, b3, W4, b4)\n",
    "    reg_cost = reg*np.sum((param*param).sum() for param in params)\n",
    "    cost = -(Y * T.log(pY)).sum() + reg_cost\n",
    "    prediction = T.argmax(pY, axis=1)\n",
    "    \n",
    "    update_W1 = W1 + mu*dW1 - lr*T.grad(cost, W1)\n",
    "    update_b1 = b1 + mu*db1 - lr*T.grad(cost, b1)\n",
    "    update_W2 = W2 + mu*dW2 - lr*T.grad(cost, W2)\n",
    "    update_b2 = b2 + mu*db2 - lr*T.grad(cost, b2)\n",
    "    update_W3 = W3 + mu*dW3 - lr*T.grad(cost, W3)\n",
    "    update_b3 = b3 + mu*db3 - lr*T.grad(cost, b3)\n",
    "    update_W4 = W4 + mu*dW4 - lr*T.grad(cost, W4)\n",
    "    update_b4 = b4 + mu*db4 - lr*T.grad(cost, b4)\n",
    "    \n",
    "    update_dW1 = mu*dW1 - lr*T.grad(cost, W1)\n",
    "    update_db1 = mu*db1 - lr*T.grad(cost, b1)\n",
    "    update_dW2 = mu*dW2 - lr*T.grad(cost, W2)\n",
    "    update_db2 = mu*db2 - lr*T.grad(cost, b2)\n",
    "    update_dW3 = mu*dW3 - lr*T.grad(cost, W3)\n",
    "    update_db3 = mu*db3 - lr*T.grad(cost, b3)\n",
    "    update_dW4 = mu*dW4 - lr*T.grad(cost, W4)\n",
    "    update_db4 = mu*db4 - lr*T.grad(cost, b4)\n",
    "    \n",
    "    train = theano.function(\n",
    "        inputs=[X, Y],\n",
    "        updates=[\n",
    "            (W1, update_W1),\n",
    "            (b1, update_b1),\n",
    "            (W2, update_W2),\n",
    "            (b2, update_b2),\n",
    "            (W3, update_W3),\n",
    "            (b3, update_b3),\n",
    "            (W4, update_W4),\n",
    "            (b4, update_b4),\n",
    "            (dW1, update_dW1),\n",
    "            (db1, update_db1),\n",
    "            (dW2, update_dW2),\n",
    "            (db2, update_db2),\n",
    "            (dW3, update_dW3),\n",
    "            (db3, update_db3),\n",
    "            (dW4, update_dW4),\n",
    "            (db4, update_db4)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    get_prediction = theano.function(\n",
    "        inputs= [X,Y],\n",
    "        outputs = [cost, prediction]\n",
    "    )\n",
    "    \n",
    "    t0 = datetime.now()\n",
    "    LL = []\n",
    "    error = []\n",
    "    for i in range(max_iter):\n",
    "        Xtrain, Ytrain = shuffle(Xtrain, Ytrain)\n",
    "        for j in range(n_batch):\n",
    "            Xbatch = Xtrain[j*batch_sz:(j*batch_sz+batch_sz),]\n",
    "            Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz+batch_sz),]\n",
    "            \n",
    "            train(Xbatch, Ybatch)\n",
    "            if j % print_period == 0:\n",
    "                cost_val, prediction_val = get_prediction(Xtest, Ytest_ind)\n",
    "                err = error_rate(prediction_val, Ytest)\n",
    "                print('Cost/err at iteration: i={}, j={}: {:.3f}/{:.3f}'.format(i,j,cost_val, err) )\n",
    "                LL.append(cost_val)\n",
    "                error.append(err)\n",
    "    print('Elapsed time: {}'.format(datetime.now() - t0))\n",
    "    plt.plot(LL)\n",
    "    plt.show()\n",
    "    plt.plot(error)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost/err at iteration: i=0, j=0: 59923.946/0.931\n",
      "Cost/err at iteration: i=0, j=10: 59109.137/0.804\n",
      "Cost/err at iteration: i=0, j=20: 58445.822/0.804\n",
      "Cost/err at iteration: i=0, j=30: 58120.189/0.822\n",
      "Cost/err at iteration: i=0, j=40: 58462.615/0.828\n",
      "Cost/err at iteration: i=0, j=50: 58355.159/0.804\n",
      "Cost/err at iteration: i=0, j=60: 58057.664/0.804\n",
      "Cost/err at iteration: i=0, j=70: 58030.737/0.804\n",
      "Cost/err at iteration: i=0, j=80: 57977.086/0.804\n",
      "Cost/err at iteration: i=0, j=90: 57920.213/0.804\n",
      "Cost/err at iteration: i=0, j=100: 57904.950/0.804\n",
      "Cost/err at iteration: i=0, j=110: 57912.967/0.804\n",
      "Cost/err at iteration: i=0, j=120: 57907.528/0.804\n",
      "Cost/err at iteration: i=0, j=130: 57898.759/0.804\n",
      "Cost/err at iteration: i=0, j=140: 57904.734/0.804\n",
      "Cost/err at iteration: i=1, j=0: 57910.825/0.804\n",
      "Cost/err at iteration: i=1, j=10: 57918.079/0.804\n",
      "Cost/err at iteration: i=1, j=20: 57922.788/0.804\n",
      "Cost/err at iteration: i=1, j=30: 57920.086/0.804\n",
      "Cost/err at iteration: i=1, j=40: 57912.437/0.804\n",
      "Cost/err at iteration: i=1, j=50: 57904.783/0.804\n",
      "Cost/err at iteration: i=1, j=60: 57897.165/0.804\n",
      "Cost/err at iteration: i=1, j=70: 57891.815/0.804\n",
      "Cost/err at iteration: i=1, j=80: 57890.085/0.804\n",
      "Cost/err at iteration: i=1, j=90: 57889.844/0.804\n",
      "Cost/err at iteration: i=1, j=100: 57891.235/0.804\n",
      "Cost/err at iteration: i=1, j=110: 57896.351/0.804\n",
      "Cost/err at iteration: i=1, j=120: 57905.375/0.804\n",
      "Cost/err at iteration: i=1, j=130: 57914.951/0.804\n",
      "Cost/err at iteration: i=1, j=140: 57921.979/0.804\n",
      "Cost/err at iteration: i=2, j=0: 57922.429/0.804\n",
      "Cost/err at iteration: i=2, j=10: 57920.855/0.804\n",
      "Cost/err at iteration: i=2, j=20: 57917.643/0.804\n",
      "Cost/err at iteration: i=2, j=30: 57910.285/0.804\n",
      "Cost/err at iteration: i=2, j=40: 57902.366/0.804\n",
      "Cost/err at iteration: i=2, j=50: 57896.576/0.804\n",
      "Cost/err at iteration: i=2, j=60: 57891.154/0.804\n",
      "Cost/err at iteration: i=2, j=70: 57887.985/0.804\n",
      "Cost/err at iteration: i=2, j=80: 57887.846/0.804\n",
      "Cost/err at iteration: i=2, j=90: 57887.542/0.804\n",
      "Cost/err at iteration: i=2, j=100: 57887.553/0.804\n",
      "Cost/err at iteration: i=2, j=110: 57890.046/0.804\n",
      "Cost/err at iteration: i=2, j=120: 57896.544/0.804\n",
      "Cost/err at iteration: i=2, j=130: 57905.282/0.804\n",
      "Cost/err at iteration: i=2, j=140: 57913.689/0.804\n",
      "Cost/err at iteration: i=3, j=0: 57915.855/0.804\n",
      "Cost/err at iteration: i=3, j=10: 57917.070/0.804\n",
      "Cost/err at iteration: i=3, j=20: 57916.532/0.804\n",
      "Cost/err at iteration: i=3, j=30: 57910.987/0.804\n",
      "Cost/err at iteration: i=3, j=40: 57903.923/0.804\n",
      "Cost/err at iteration: i=3, j=50: 57898.332/0.804\n",
      "Cost/err at iteration: i=3, j=60: 57892.428/0.804\n",
      "Cost/err at iteration: i=3, j=70: 57888.404/0.804\n",
      "Cost/err at iteration: i=3, j=80: 57888.068/0.804\n",
      "Cost/err at iteration: i=3, j=90: 57888.074/0.804\n",
      "Cost/err at iteration: i=3, j=100: 57888.545/0.804\n",
      "Cost/err at iteration: i=3, j=110: 57891.507/0.804\n",
      "Cost/err at iteration: i=3, j=120: 57897.560/0.804\n",
      "Cost/err at iteration: i=3, j=130: 57905.026/0.804\n",
      "Cost/err at iteration: i=3, j=140: 57911.688/0.804\n",
      "Cost/err at iteration: i=4, j=0: 57913.103/0.804\n",
      "Cost/err at iteration: i=4, j=10: 57913.691/0.804\n",
      "Cost/err at iteration: i=4, j=20: 57913.252/0.804\n",
      "Cost/err at iteration: i=4, j=30: 57908.721/0.804\n",
      "Cost/err at iteration: i=4, j=40: 57902.888/0.804\n",
      "Cost/err at iteration: i=4, j=50: 57898.308/0.804\n",
      "Cost/err at iteration: i=4, j=60: 57893.221/0.804\n",
      "Cost/err at iteration: i=4, j=70: 57889.635/0.804\n",
      "Cost/err at iteration: i=4, j=80: 57889.124/0.804\n",
      "Cost/err at iteration: i=4, j=90: 57888.832/0.804\n",
      "Cost/err at iteration: i=4, j=100: 57889.231/0.804\n",
      "Cost/err at iteration: i=4, j=110: 57892.259/0.804\n",
      "Cost/err at iteration: i=4, j=120: 57898.592/0.804\n",
      "Cost/err at iteration: i=4, j=130: 57906.278/0.804\n",
      "Cost/err at iteration: i=4, j=140: 57913.015/0.804\n",
      "Cost/err at iteration: i=5, j=0: 57914.348/0.804\n",
      "Cost/err at iteration: i=5, j=10: 57914.555/0.804\n",
      "Cost/err at iteration: i=5, j=20: 57913.533/0.804\n",
      "Cost/err at iteration: i=5, j=30: 57908.355/0.804\n",
      "Cost/err at iteration: i=5, j=40: 57902.034/0.804\n",
      "Cost/err at iteration: i=5, j=50: 57897.262/0.804\n",
      "Cost/err at iteration: i=5, j=60: 57892.223/0.804\n",
      "Cost/err at iteration: i=5, j=70: 57888.845/0.804\n",
      "Cost/err at iteration: i=5, j=80: 57888.626/0.804\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-bc324413e51d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mYbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYtrain_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_period\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mcost_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
